{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import glob\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd512_Siamese import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation, SSDDataAugmentation_Siamese\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "img_height = 512  # Height of the model input images\n",
    "img_width = 512  # Width of the model input images\n",
    "img_channels = 3  # Number of color channels of the model input images\n",
    "mean_color = [123, 117, 104]  # Per-channel mean of images. Do not change if use any of the pre-trained weights.\n",
    "# The color channel order in the original SSD is BGR,\n",
    "# so we'll have the model reverse the color channel order of the input images.\n",
    "swap_channels = [2, 1, 0]\n",
    "# The anchor box scaling factors used in the original SSD512 for the Pascal VOC datasets\n",
    "# scales_pascal =\n",
    "# The anchor box scaling factors used in the original SSD512 for the MS COCO datasets\n",
    "scales_coco = [0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05]\n",
    "scales = scales_coco\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0 / 3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]]  # The anchor box aspect ratios used in the original SSD512; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [8, 16, 32, 64, 128, 256, 512]  # Space between two adjacent anchor box center points for each predictor layer.\n",
    "# The offsets of the first anchor box center points from the top and left borders of the image\n",
    "# as a fraction of the step size for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "clip_boxes = False  # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "# The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "variances = [0.1, 0.1, 0.2, 0.2]\n",
    "normalize_coords = True\n",
    "Model_Build = 'New_Model'  # 'Load_Model'\n",
    "Optimizer_Type = 'SGD'  # 'Adam'  #\n",
    "# Different batch_size will have different prediction loss.\n",
    "batch_size = 6  # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "# alpha_distance = 0.0001  # Coefficient for the distance between the source and target feature maps.\n",
    "G_loss_weights = [0.001, 1.0]\n",
    "D_loss_weights = [0.001, 0.001]\n",
    "\n",
    "# 'City_to_foggy0_01_resize_600_1200' # 'City_to_foggy0_02_resize_600_1200'  # 'SIM10K_to_VOC07'\n",
    "# 'SIM10K'  # 'Cityscapes_foggy_beta_0_01'  #  'City_to_foggy0_02_resize_400_800'\n",
    "# 'SIM10K_to_VOC12_resize_400_800'\n",
    "DatasetName = 'SIM10K_to_City_resize_400_800' # 'SIM10K_to_VOC07_resize_400_800'  # 'City_to_foggy0_01_resize_400_800'  # \n",
    "processed_dataset_path = './processed_dataset_h5/' + DatasetName\n",
    "if not os.path.exists(processed_dataset_path):\n",
    "    os.makedirs(processed_dataset_path)\n",
    "\n",
    "checkpoint_path = '../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001'\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "csv_file_name = 'training_log.csv'    \n",
    "    \n",
    "if len(glob.glob(os.path.join(processed_dataset_path, '*.h5'))):\n",
    "    Dataset_Build = 'Load_Dataset'\n",
    "else:\n",
    "    Dataset_Build = 'New_Dataset'\n",
    "\n",
    "if DatasetName == 'SIM10K_to_VOC12_resize_400_800':\n",
    "    resize_image_to = (400, 800)\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/SIM10K/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/VOCdevkit/VOC2012/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/VOCdevkit/VOC2012/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/SIM10K/Annotations'\n",
    "    test_annotation_dir = '../../datasets/VOCdevkit/VOC2012/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/SIM10K/ImageSets/Main/trainval10k.txt'\n",
    "    # The trainset of VOC which has 'car' object is used as train_target.\n",
    "    train_target_image_set_filename = '../../datasets/VOCdevkit/VOC2012_CAR/ImageSets/Main/train_target.txt'\n",
    "    # The valset of VOC which has 'car' object is used as test.\n",
    "    test_target_image_set_filename = '../../datasets/VOCdevkit/VOC2012_CAR/ImageSets/Main/test.txt'\n",
    "\n",
    "    classes = ['background', 'car']  # Our model will produce predictions for these classes.\n",
    "    train_classes = ['background', 'car', 'motorbike', 'person']  # The train_source dataset contains these classes.\n",
    "    train_include_classes = [train_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # The test_target dataset contains these classes.\n",
    "    val_classes = ['background', 'car',\n",
    "                   'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                   'bottle', 'bus', 'cat',\n",
    "                   'chair', 'cow', 'diningtable', 'dog',\n",
    "                   'horse', 'motorbike', 'person', 'pottedplant',\n",
    "                   'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "    val_include_classes = [val_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'SIM10K_to_VOC07_resize_400_800':\n",
    "    resize_image_to = (400, 800)\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/SIM10K/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/VOCdevkit/VOC2007/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/VOCdevkit/VOC2007/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/SIM10K/Annotations'\n",
    "    test_annotation_dir = '../../datasets/VOCdevkit/VOC2007/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/SIM10K/ImageSets/Main/trainval10k.txt'\n",
    "    # The trainset of VOC which has 'car' object is used as train_target.\n",
    "    train_target_image_set_filename = '../../datasets/VOCdevkit/VOC2007_CAR/ImageSets/Main/train_target.txt'\n",
    "    # The valset of VOC which has 'car' object is used as test.\n",
    "    test_target_image_set_filename = '../../datasets/VOCdevkit/VOC2007_CAR/ImageSets/Main/test.txt'\n",
    "\n",
    "    classes = ['background', 'car']  # Our model will produce predictions for these classes.\n",
    "    train_classes = ['background', 'car', 'motorbike', 'person']  # The train_source dataset contains these classes.\n",
    "    train_include_classes = [train_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # The test_target dataset contains these classes.\n",
    "    val_classes = ['background', 'car',\n",
    "                   'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                   'bottle', 'bus', 'cat',\n",
    "                   'chair', 'cow', 'diningtable', 'dog',\n",
    "                   'horse', 'motorbike', 'person', 'pottedplant',\n",
    "                   'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "    val_include_classes = [val_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'SIM10K_to_City_resize_400_800':\n",
    "    resize_image_to = (400, 800)\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/SIM10K/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/val_data_for_SIM10K_to_cityscapes/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/SIM10K/Annotations'\n",
    "    test_annotation_dir = '../../datasets/val_data_for_SIM10K_to_cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/SIM10K/ImageSets/Main/trainval10k.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    test_target_image_set_filename = '../../datasets/val_data_for_SIM10K_to_cityscapes/ImageSets/Main/test.txt'\n",
    "\n",
    "    classes = ['background', 'car']  # Our model will produce predictions for these classes.\n",
    "    train_classes = ['background', 'car', 'motorbike', 'person']  # The train_source dataset contains these classes.\n",
    "    train_include_classes = [train_classes.index(one_class) for one_class in classes[1:]]\n",
    "    # The test_target dataset contains these classes.\n",
    "    val_classes = ['background', 'car']\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'City_to_foggy0_02_resize_400_800':\n",
    "    resize_image_to = (400, 800)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "elif DatasetName == 'City_to_foggy0_01_resize_400_800':\n",
    "    resize_image_to = (400, 800)\n",
    "    # Introduction of PascalVOC: https://arleyzhang.github.io/articles/1dc20586/\n",
    "    # The directories that contain the images.\n",
    "    train_source_images_dir = '../../datasets/Cityscapes/JPEGImages'\n",
    "    train_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "    test_target_images_dir = '../../datasets/CITYSCAPES_beta_0_01/JPEGImages'\n",
    "\n",
    "    # The directories that contain the annotations.\n",
    "    train_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "    test_annotation_dir = '../../datasets/Cityscapes/Annotations'\n",
    "\n",
    "    # The paths to the image sets.\n",
    "    train_source_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_source.txt'\n",
    "    train_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/train_target.txt'\n",
    "    test_target_image_set_filename = '../../datasets/Cityscapes/ImageSets/Main/test.txt'\n",
    "    # Our model will produce predictions for these classes.\n",
    "    classes = ['background',\n",
    "               'person', 'rider', 'car', 'truck',\n",
    "               'bus', 'train', 'motorcycle', 'bicycle']\n",
    "    train_classes = classes\n",
    "    train_include_classes = 'all'\n",
    "    val_classes = classes\n",
    "    val_include_classes = 'all'\n",
    "    # Number of positive classes, 8 for domain Cityscapes, 20 for Pascal VOC, 80 for MS COCO, 1 for SIM10K\n",
    "    n_classes = len(classes) - 1\n",
    "\n",
    "else:\n",
    "    raise ValueError('Undefined dataset name.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_network is Conv2\n"
     ]
    }
   ],
   "source": [
    "if Model_Build == 'New_Model':\n",
    "    # 1: Build the Keras model.\n",
    "\n",
    "    K.clear_session()  # Clear previous models from memory.\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "    D_model, G_model = ssd_512(image_size=(img_height, img_width, img_channels),\n",
    "                               n_classes=n_classes,\n",
    "                               G_loss_weights=G_loss_weights,\n",
    "                               D_loss_weights=D_loss_weights,\n",
    "                               mode='training',\n",
    "                               l2_regularization=0.0005,\n",
    "                               scales=scales,\n",
    "                               aspect_ratios_per_layer=aspect_ratios,\n",
    "                               two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                               steps=steps,\n",
    "                               offsets=offsets,\n",
    "                               clip_boxes=clip_boxes,\n",
    "                               variances=variances,\n",
    "                               normalize_coords=normalize_coords,\n",
    "                               subtract_mean=mean_color,\n",
    "                               swap_channels=swap_channels)\n",
    "\n",
    "else:\n",
    "    raise ValueError('Undefined Model_Build. Model_Build should be New_Model  or Load_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source labels: 100%|██████████| 10000/10000 [00:02<00:00, 4218.49it/s]\n",
      "Loading source image IDs: 100%|██████████| 10000/10000 [00:00<00:00, 10582.58it/s]\n",
      "Loading target image IDs: 100%|██████████| 2966/2966 [00:00<00:00, 10745.99it/s]\n",
      "Loading evaluation-neutrality annotations: 100%|██████████| 10000/10000 [00:01<00:00, 7772.42it/s]\n",
      "Loading source labels: 100%|██████████| 479/479 [00:00<00:00, 3990.50it/s]\n",
      "Loading source image IDs: 100%|██████████| 479/479 [00:00<00:00, 7969.19it/s]\n",
      "Loading target image IDs: 0it [00:00, ?it/s]\n",
      "Loading evaluation-neutrality annotations: 100%|██████████| 479/479 [00:00<00:00, 7501.97it/s]\n"
     ]
    }
   ],
   "source": [
    "if Dataset_Build == 'New_Dataset':\n",
    "    # 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "    # Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "    train_dataset = DataGenerator(dataset='train', load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "    val_dataset = DataGenerator(dataset='val', load_images_into_memory=False, hdf5_dataset_path=None)\n",
    "\n",
    "    # 2: Parse the image and label lists for the training and validation datasets. This can take a while.\n",
    "    # images_dirs, image_set_filenames, and annotations_dirs should have the same length\n",
    "    train_dataset.parse_xml(images_dirs=[train_source_images_dir],\n",
    "                            target_images_dirs=[train_target_images_dir],\n",
    "                            image_set_filenames=[train_source_image_set_filename],\n",
    "                            target_image_set_filenames=[train_target_image_set_filename],\n",
    "                            annotations_dirs=[train_annotation_dir],\n",
    "                            classes=train_classes,\n",
    "                            include_classes=train_include_classes,\n",
    "                            exclude_truncated=False,\n",
    "                            exclude_difficult=False,\n",
    "                            ret=False)\n",
    "\n",
    "    val_dataset.parse_xml(images_dirs=[test_target_images_dir],\n",
    "                          image_set_filenames=[test_target_image_set_filename],\n",
    "                          annotations_dirs=[test_annotation_dir],\n",
    "                          classes=val_classes,\n",
    "                          include_classes=val_include_classes,\n",
    "                          exclude_truncated=False,\n",
    "                          exclude_difficult=True,\n",
    "                          ret=False)\n",
    "\n",
    "    # Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "    # speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "    # option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "    # want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "    # After create these h5 files, if you have resized the input image, you need to reload these files. Otherwise,\n",
    "    # the images and the labels will not change.\n",
    "\n",
    "    train_dataset.create_hdf5_dataset(file_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                      resize=resize_image_to,\n",
    "                                      variable_image_size=True,\n",
    "                                      verbose=True)\n",
    "\n",
    "    val_dataset.create_hdf5_dataset(file_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                    resize=False,\n",
    "                                    variable_image_size=True,\n",
    "                                    verbose=True)\n",
    "\n",
    "    train_dataset = DataGenerator(dataset='train',\n",
    "                                  load_images_into_memory=False,\n",
    "                                  hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                  filenames=train_source_image_set_filename,\n",
    "                                  target_filenames=train_target_image_set_filename,\n",
    "                                  filenames_type='text',\n",
    "                                  images_dir=train_source_images_dir,\n",
    "                                  target_images_dir=train_target_images_dir)\n",
    "\n",
    "    val_dataset = DataGenerator(dataset='val',\n",
    "                                load_images_into_memory=False,\n",
    "                                hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                filenames=test_target_image_set_filename,\n",
    "                                filenames_type='text',\n",
    "                                images_dir=test_target_images_dir)\n",
    "\n",
    "elif Dataset_Build == 'Load_Dataset':\n",
    "    # 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "    # Load dataset from the created h5 file.\n",
    "    train_dataset = DataGenerator(dataset='train',\n",
    "                                  load_images_into_memory=False,\n",
    "                                  hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_train.h5'),\n",
    "                                  filenames=train_source_image_set_filename,\n",
    "                                  target_filenames=train_target_image_set_filename,\n",
    "                                  filenames_type='text',\n",
    "                                  images_dir=train_source_images_dir,\n",
    "                                  target_images_dir=train_target_images_dir)\n",
    "\n",
    "    val_dataset = DataGenerator(dataset='val',\n",
    "                                load_images_into_memory=False,\n",
    "                                hdf5_dataset_path=os.path.join(processed_dataset_path, 'dataset_test.h5'),\n",
    "                                filenames=test_target_image_set_filename,\n",
    "                                filenames_type='text',\n",
    "                                images_dir=test_target_images_dir)\n",
    "\n",
    "else:\n",
    "    raise ValueError('Undefined Dataset_Build. Dataset_Build should be New_Dataset or Load_Dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t 10000\n",
      "Number of images in the validation dataset:\t   479\n"
     ]
    }
   ],
   "source": [
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation_Siamese(img_height=img_height,\n",
    "                                                    img_width=img_width)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [G_model.get_layer('conv4_3_norm_mbox_conf').output_shape[1:3],\n",
    "                   G_model.get_layer('fc7_mbox_conf').output_shape[1:3],\n",
    "                   G_model.get_layer('conv6_2_mbox_conf').output_shape[1:3],\n",
    "                   G_model.get_layer('conv7_2_mbox_conf').output_shape[1:3],\n",
    "                   G_model.get_layer('conv8_2_mbox_conf').output_shape[1:3],\n",
    "                   G_model.get_layer('conv9_2_mbox_conf').output_shape[1:3],\n",
    "                   G_model.get_layer('conv10_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "# The input image and label are first processed by transformations. Then, the label will be further encoded by\n",
    "# ssd_input_encoder. The encoded labels are classId and offset to each anchor box.\n",
    "# G_train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "#                                            generator_type='G',\n",
    "#                                            shuffle=True,\n",
    "#                                            transformations=[ssd_data_augmentation],\n",
    "#                                            label_encoder=ssd_input_encoder,\n",
    "#                                            returns={'processed_images',\n",
    "#                                                     'encoded_labels'},\n",
    "#                                            keep_images_without_gt=False)\n",
    "\n",
    "# D_train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "#                                            generator_type='D',\n",
    "#                                            shuffle=True,\n",
    "#                                            transformations=[ssd_data_augmentation],\n",
    "#                                            label_encoder=ssd_input_encoder,\n",
    "#                                            returns={'processed_images',\n",
    "#                                                     'encoded_labels'},\n",
    "#                                            keep_images_without_gt=False)\n",
    "\n",
    "# val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "#                                      generator_type='G',\n",
    "#                                      shuffle=False,\n",
    "#                                      transformations=[convert_to_3_channels,\n",
    "#                                                       resize],\n",
    "#                                      label_encoder=ssd_input_encoder,\n",
    "#                                      returns={'processed_images',\n",
    "#                                               'encoded_labels'},\n",
    "#                                      keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochss_real = 120\n",
    "steps_per_G_epoch = 100\n",
    "steps_per_D_epoch = 10\n",
    "initial_epoch = 0\n",
    "final_epoch = int(num_epochss_real * 370.0 / steps_per_G_epoch)\n",
    "val_freq = int(final_epoch / num_epochss_real)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 20:\n",
    "        return 0.0005    \n",
    "    elif epoch < int(0.7 * final_epoch):\n",
    "        return 0.001\n",
    "    elif epoch < int(0.9 * final_epoch):\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001\n",
    "\n",
    "# def lr_schedule(epoch):\n",
    "#     if epoch < 20:\n",
    "#         return 0.0005\n",
    "#     elif epoch < 800:\n",
    "#         return 0.001\n",
    "#     elif epoch < 1000:\n",
    "#         return 0.0001\n",
    "#     else:\n",
    "#         return 0.00001\n",
    "\n",
    "# Define model callbacks.\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath=os.path.join(checkpoint_path, 'epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5'),\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=False,\n",
    "                                   save_weights_only=True,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "# model_checkpoint.best to the best validation loss from the previous training\n",
    "# model_checkpoint.best = 4.83704\n",
    "\n",
    "csv_logger = CSVLogger(filename=os.path.join(checkpoint_path, csv_file_name),\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule,\n",
    "                                                verbose=1)\n",
    "\n",
    "terminate_on_nan = TerminateOnNaN()\n",
    "\n",
    "TensorBoard_monitor = TensorBoard(log_dir=checkpoint_path)\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             learning_rate_scheduler,\n",
    "             terminate_on_nan,\n",
    "             TensorBoard_monitor]\n",
    "\n",
    "callbacks_no_val = [learning_rate_scheduler,\n",
    "                    terminate_on_nan]\n",
    "\n",
    "# def lr_schedule_D(epoch):\n",
    "#     return 0.0005\n",
    "\n",
    "\n",
    "# learning_rate_scheduler_D = LearningRateScheduler(schedule=lr_schedule_D,\n",
    "#                                                   verbose=1)\n",
    "\n",
    "# callbacks_no_val_D = [learning_rate_scheduler_D,\n",
    "#                       terminate_on_nan]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 1/1\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 79s 791ms/step - loss: 19.3366 - D_model_loss: 0.0596 - predictions_loss: 15.7406\n",
      "\n",
      "\n",
      "Train discriminator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 8s 772ms/step - loss: 0.3766 - lambda_3_loss: 15.9424 - lambda_4_loss: 0.7910\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0005.\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 3/3\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 73s 725ms/step - loss: 18.8411 - D_model_loss: 1.1921e-07 - predictions_loss: 15.2461\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 3/3\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.3755 - lambda_3_loss: 15.9424 - lambda_4_loss: 2.4182e-04\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 4/4\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 99s 993ms/step - loss: 18.6124 - D_model_loss: 1.1641e-06 - predictions_loss: 15.0208 - val_loss: 17.4323 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 13.8424\n",
      "\n",
      "Epoch 00004: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-04_loss-18.6124_val_loss-17.4323.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 4/4\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 358ms/step - loss: 0.3755 - lambda_3_loss: 15.9424 - lambda_4_loss: 0.2686\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 5/5\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 17.9627 - D_model_loss: 1.1921e-07 - predictions_loss: 14.3745\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 5/5\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.3752 - lambda_3_loss: 15.9424 - lambda_4_loss: 0.2052\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 6/6\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 73s 733ms/step - loss: 17.0299 - D_model_loss: 1.1921e-07 - predictions_loss: 13.4451\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 6/6\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 0.3747 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.9471e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 105s 1s/step - loss: 17.7712 - D_model_loss: 1.2596e-07 - predictions_loss: 14.1897 - val_loss: 16.8276 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 13.2476\n",
      "\n",
      "Epoch 00007: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-07_loss-17.7801_val_loss-16.8276.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 7/7\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.3744 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 8/8\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 16.9410 - D_model_loss: 9.0936e-07 - predictions_loss: 13.3625\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 8/8\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.3741 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 9/9\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 70s 704ms/step - loss: 13.6706 - D_model_loss: 0.0269 - predictions_loss: 10.0953\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 9/9\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.3738 - lambda_3_loss: 15.9424 - lambda_4_loss: 6.0847e-06\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 107s 1s/step - loss: 10.1253 - D_model_loss: 1.2120e-07 - predictions_loss: 6.5530 - val_loss: 10.8049 - val_D_model_loss: 0.0078 - val_predictions_loss: 7.2341\n",
      "\n",
      "Epoch 00010: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-10_loss-10.1300_val_loss-10.8049.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.3735 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.3312e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 11/11\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 71s 714ms/step - loss: 9.9029 - D_model_loss: 1.7901e-07 - predictions_loss: 6.3337\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 11/11\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 388ms/step - loss: 0.3732 - lambda_3_loss: 15.9424 - lambda_4_loss: 6.8906e-06\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 12/12\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 71s 714ms/step - loss: 9.1224 - D_model_loss: 1.1921e-07 - predictions_loss: 5.5565\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 12/12\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 8s 840ms/step - loss: 0.3730 - lambda_3_loss: 15.9424 - lambda_4_loss: 3.8618e-06\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 13/13\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 101s 1s/step - loss: 9.4876 - D_model_loss: 1.2259e-07 - predictions_loss: 5.9249 - val_loss: 10.9399 - val_D_model_loss: 4.5008e-06 - val_predictions_loss: 7.3788\n",
      "\n",
      "Epoch 00013: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-13_loss-9.4903_val_loss-10.9399.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 13/13\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.3729 - lambda_3_loss: 15.9424 - lambda_4_loss: 0.1963\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 14/14\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 8.9276 - D_model_loss: 1.1921e-07 - predictions_loss: 5.3681\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 14/14\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.3724 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.2120e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 15/15\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 71s 711ms/step - loss: 8.7462 - D_model_loss: 2.1718e-06 - predictions_loss: 5.1899\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 15/15\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 7s 656ms/step - loss: 0.3722 - lambda_3_loss: 15.9424 - lambda_4_loss: 7.8481e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 121s 1s/step - loss: 9.0799 - D_model_loss: 1.1921e-07 - predictions_loss: 5.5268 - val_loss: 9.3918 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.8403\n",
      "\n",
      "Epoch 00016: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-16_loss-9.0807_val_loss-9.3918.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 0.3719 - lambda_3_loss: 15.9424 - lambda_4_loss: 0.0363\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 17/17\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 74s 736ms/step - loss: 8.6315 - D_model_loss: 1.1921e-07 - predictions_loss: 5.0816\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 17/17\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.3716 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.7087e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 18/18\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 73s 732ms/step - loss: 8.9423 - D_model_loss: 1.1921e-07 - predictions_loss: 5.3956\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 18/18\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.3714 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 19/19\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 122s 1s/step - loss: 8.6377 - D_model_loss: 1.1921e-07 - predictions_loss: 5.0942 - val_loss: 8.9130 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.3711\n",
      "\n",
      "Epoch 00019: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-19_loss-8.6398_val_loss-8.9130.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 19/19\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 3s 325ms/step - loss: 0.3711 - lambda_3_loss: 15.9424 - lambda_4_loss: 4.7287e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0005.\n",
      "100/100 [==============================] - 70s 702ms/step - loss: 8.5427 - D_model_loss: 1.3133e-07 - predictions_loss: 5.0023\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0005.\n",
      "10/10 [==============================] - 3s 343ms/step - loss: 0.3709 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 21/21\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 9.9365 - D_model_loss: 5.8052e-07 - predictions_loss: 6.4003\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 21/21\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.3704 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 22/22\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 219s 2s/step - loss: 10.2503 - D_model_loss: 1.8438e-07 - predictions_loss: 6.7186 - val_loss: 10.1497 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 6.6202\n",
      "\n",
      "Epoch 00022: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-22_loss-10.2480_val_loss-10.1497.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 22/22\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 0.3699 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.2716e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 23/23\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 9.3452 - D_model_loss: 1.1921e-07 - predictions_loss: 5.8185\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 23/23\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.3695 - lambda_3_loss: 15.9424 - lambda_4_loss: 2.0724e-06\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 24/24\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 8.9654 - D_model_loss: 3.5487e-07 - predictions_loss: 5.4444\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 24/24\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 365ms/step - loss: 0.3689 - lambda_3_loss: 15.8241 - lambda_4_loss: 4.0649e-05\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 25/25\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 98s 976ms/step - loss: 8.8825 - D_model_loss: 1.6193e-07 - predictions_loss: 5.3675 - val_loss: 9.4336 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.9215\n",
      "\n",
      "Epoch 00025: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-25_loss-8.8820_val_loss-9.4336.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 25/25\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.3685 - lambda_3_loss: 15.9424 - lambda_4_loss: 5.8214e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 26/26\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 705ms/step - loss: 8.7328 - D_model_loss: 1.4166e-07 - predictions_loss: 5.2237\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 26/26\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.3680 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 27/27\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 8.8749 - D_model_loss: 1.9491e-07 - predictions_loss: 5.3718\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 27/27\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.3675 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 28/28\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 101s 1s/step - loss: 8.7651 - D_model_loss: 2.7836e-07 - predictions_loss: 5.2680 - val_loss: 12.6686 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 9.1744\n",
      "\n",
      "Epoch 00028: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-28_loss-8.7651_val_loss-12.6686.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 28/28\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 3s 306ms/step - loss: 0.3670 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 29/29\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 9.1245 - D_model_loss: 1.2032e-07 - predictions_loss: 5.6326\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 29/29\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 400ms/step - loss: 0.3664 - lambda_3_loss: 15.8107 - lambda_4_loss: 1.8570e-04\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 8.4597 - D_model_loss: 5.6365e-07 - predictions_loss: 4.9735\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.3660 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 31/31\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 102s 1s/step - loss: 8.5480 - D_model_loss: 1.2060e-07 - predictions_loss: 5.0678 - val_loss: 9.5143 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 6.0371\n",
      "\n",
      "Epoch 00031: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-31_loss-8.5480_val_loss-9.5143.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 31/31\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.3655 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 32/32\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 33/33\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 8.2688 - D_model_loss: 1.1921e-07 - predictions_loss: 4.7946\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 33/33\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 8s 785ms/step - loss: 0.3650 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 34/34\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 111s 1s/step - loss: 8.4320 - D_model_loss: 1.1941e-07 - predictions_loss: 4.9637 - val_loss: 8.9155 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.4502\n",
      "\n",
      "Epoch 00034: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-34_loss-8.4325_val_loss-8.9155.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 34/34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.3645 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.2318e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 8.1925 - D_model_loss: 1.2219e-07 - predictions_loss: 4.7302\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.3639 - lambda_3_loss: 15.8402 - lambda_4_loss: 8.7119e-05\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 36/36\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 72s 724ms/step - loss: 7.9861 - D_model_loss: 3.6540e-05 - predictions_loss: 4.5299\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 36/36\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 6s 571ms/step - loss: 0.3635 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 37/37\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 38/38\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 73s 726ms/step - loss: 8.3332 - D_model_loss: 1.1921e-07 - predictions_loss: 4.8831\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 38/38\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 0.3631 - lambda_3_loss: 15.9424 - lambda_4_loss: 2.2069e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 39/39\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 74s 736ms/step - loss: 8.1663 - D_model_loss: 6.7828e-07 - predictions_loss: 4.7222\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 39/39\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3626 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 40/40\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 158s 2s/step - loss: 8.1445 - D_model_loss: 1.7067e-07 - predictions_loss: 4.7063 - val_loss: 8.7067 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.2715\n",
      "\n",
      "Epoch 00040: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-40_loss-8.1462_val_loss-8.7067.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 40/40\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 0.3621 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 41/41\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 7.9496 - D_model_loss: 1.2020e-07 - predictions_loss: 4.5175\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 41/41\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 0.3616 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 42/42\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 713ms/step - loss: 7.9165 - D_model_loss: 1.2974e-07 - predictions_loss: 4.4901\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 42/42\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 0.3611 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 43/43\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 98s 979ms/step - loss: 7.9692 - D_model_loss: 1.2040e-07 - predictions_loss: 4.5489 - val_loss: 9.2914 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.8741\n",
      "\n",
      "Epoch 00043: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-43_loss-7.9692_val_loss-9.2914.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 43/43\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 6s 624ms/step - loss: 0.3605 - lambda_3_loss: 15.8081 - lambda_4_loss: 2.5652e-06\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 44/44\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 45/45\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 8.1293 - D_model_loss: 7.3366e-07 - predictions_loss: 4.7149\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 45/45\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 7s 651ms/step - loss: 0.3602 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 46/46\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 114s 1s/step - loss: 7.8613 - D_model_loss: 1.9038e-06 - predictions_loss: 4.4530 - val_loss: 8.8979 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.4926\n",
      "\n",
      "Epoch 00046: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-46_loss-7.8613_val_loss-8.8979.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 46/46\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 0.3597 - lambda_3_loss: 15.9424 - lambda_4_loss: 2.4256e-06\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 47/47\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 711ms/step - loss: 7.8208 - D_model_loss: 7.4477e-07 - predictions_loss: 4.4185\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 47/47\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 360ms/step - loss: 0.3592 - lambda_3_loss: 15.9424 - lambda_4_loss: 5.5632e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 48/48\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 49/49\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 99s 986ms/step - loss: 7.7951 - D_model_loss: 4.2531e-07 - predictions_loss: 4.3988 - val_loss: 8.6351 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.2418\n",
      "\n",
      "Epoch 00049: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-49_loss-7.7951_val_loss-8.6351.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 49/49\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.3587 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.9909e-06\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 7.8142 - D_model_loss: 1.1981e-07 - predictions_loss: 4.4239\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 0.3582 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 51/51\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 7.7732 - D_model_loss: 1.3312e-07 - predictions_loss: 4.3890\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 51/51\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 5s 495ms/step - loss: 0.3577 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 52/52\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 105s 1s/step - loss: 7.7759 - D_model_loss: 2.5056e-06 - predictions_loss: 4.3975 - val_loss: 8.8180 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.4427\n",
      "\n",
      "Epoch 00052: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-52_loss-7.7765_val_loss-8.8180.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 52/52\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 347ms/step - loss: 0.3573 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 53/53\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 7.7593 - D_model_loss: 1.2577e-07 - predictions_loss: 4.3870\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 53/53\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 384ms/step - loss: 0.3568 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 54/54\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 711ms/step - loss: 7.6415 - D_model_loss: 1.1961e-07 - predictions_loss: 4.2751\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 54/54\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3563 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.8999e-05\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 55/55\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 109s 1s/step - loss: 7.8682 - D_model_loss: 1.7842e-07 - predictions_loss: 4.5076 - val_loss: 8.8377 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.4801\n",
      "\n",
      "Epoch 00055: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-55_loss-7.8687_val_loss-8.8377.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 55/55\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.3558 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 56/56\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 706ms/step - loss: 7.6727 - D_model_loss: 1.5001e-07 - predictions_loss: 4.3182\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 56/56\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 356ms/step - loss: 0.3553 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.3096e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 57/57\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 71s 714ms/step - loss: 7.8158 - D_model_loss: 3.8643e-05 - predictions_loss: 4.4672\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 57/57\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 3s 322ms/step - loss: 0.3549 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 58/58\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "100/100 [==============================] - 108s 1s/step - loss: 7.7345 - D_model_loss: 2.7698e-05 - predictions_loss: 4.3919 - val_loss: 8.8167 - val_D_model_loss: 1.1921e-07 - val_predictions_loss: 5.4770\n",
      "\n",
      "Epoch 00058: saving model to ../trained_weights/SIM10K_to_City/current/G100_D10_GD_weights0_001/epoch-58_loss-7.7357_val_loss-8.8167.h5\n",
      "\n",
      "\n",
      "Train discriminator.\n",
      "Epoch 58/58\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.3544 - lambda_3_loss: 15.9424 - lambda_4_loss: 1.1921e-07\n",
      "\n",
      "\n",
      "Train generator.\n",
      "Epoch 59/59\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
      " 93/100 [==========================>...] - ETA: 4s - loss: 8.0072 - D_model_loss: 1.4955e-07 - predictions_loss: 4.6700"
     ]
    }
   ],
   "source": [
    "for initial_epoch in range(final_epoch):\n",
    "    try:\n",
    "        print('\\n')\n",
    "        print('Train generator.')\n",
    "        G_train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                                   generator_type='G',\n",
    "                                                   shuffle=True,\n",
    "                                                   transformations=[ssd_data_augmentation],\n",
    "                                                   label_encoder=ssd_input_encoder,\n",
    "                                                   returns={'processed_images',\n",
    "                                                            'encoded_labels'},\n",
    "                                                   keep_images_without_gt=False)  \n",
    "\n",
    "        if initial_epoch != 0 and initial_epoch % val_freq == 0:\n",
    "            val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                                 generator_type='G',\n",
    "                                                 shuffle=False,\n",
    "                                                 transformations=[convert_to_3_channels,\n",
    "                                                                  resize],\n",
    "                                                 label_encoder=ssd_input_encoder,\n",
    "                                                 returns={'processed_images',\n",
    "                                                          'encoded_labels'},\n",
    "                                                 keep_images_without_gt=False)  \n",
    "\n",
    "            history_G = G_model.fit_generator(generator=G_train_generator,\n",
    "                                              steps_per_epoch=steps_per_G_epoch,\n",
    "                                              epochs=initial_epoch+1,\n",
    "                                              callbacks=callbacks,\n",
    "                                              validation_data=val_generator,\n",
    "                                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                                              initial_epoch=initial_epoch)\n",
    "\n",
    "        else:\n",
    "            history_G = G_model.fit_generator(generator=G_train_generator,\n",
    "                                              steps_per_epoch=steps_per_G_epoch,\n",
    "                                              epochs=initial_epoch+1,\n",
    "                                              callbacks=callbacks_no_val,\n",
    "                                              initial_epoch=initial_epoch)\n",
    "\n",
    "        print('\\n')\n",
    "        print( 'Train discriminator.')\n",
    "        D_train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                                   generator_type='D',\n",
    "                                                   shuffle=True,\n",
    "                                                   transformations=[ssd_data_augmentation],\n",
    "                                                   label_encoder=ssd_input_encoder,\n",
    "                                                   returns={'processed_images',\n",
    "                                                            'encoded_labels'},\n",
    "                                                   keep_images_without_gt=False)        \n",
    "\n",
    "        history_D = D_model.fit_generator(generator=D_train_generator,\n",
    "                                          steps_per_epoch=steps_per_D_epoch,\n",
    "                                          epochs=initial_epoch+1,\n",
    "                                          callbacks=callbacks_no_val,\n",
    "                                          initial_epoch=initial_epoch)\n",
    "\n",
    "    except ValueError:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Set the generator for the val_dataset or train_dataset predictions.\n",
    "\n",
    "predict_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=None,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'filenames',\n",
    "                                                  'inverse_transform',\n",
    "                                                  'original_images',\n",
    "                                                  'original_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "# 2: Generate samples.\n",
    "\n",
    "batch_images, batch_filenames, batch_inverse_transforms, batch_original_images, batch_original_labels = next(predict_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images, batch_filenames, batch_inverse_transforms, batch_original_images, batch_original_labels = next(predict_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "print(\"Image:\", batch_filenames[i])\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_images[0][i])\n",
    "plt.show()\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_images[1][i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # Which batch item to look at\n",
    "\n",
    "print(\"Image:\", batch_filenames[i])\n",
    "print()\n",
    "print(\"Ground truth boxes:\\n\")\n",
    "print(np.array(batch_original_labels[i]))\n",
    "\n",
    "# 3: Make predictions.\n",
    "\n",
    "y_pred = model.predict(batch_images)[-1]\n",
    "\n",
    "# Now let's decode the raw predictions in `y_pred`.\n",
    "\n",
    "# Had we created the model in 'inference' or 'inference_fast' mode,\n",
    "# then the model's final layer would be a `DecodeDetections` layer and\n",
    "# `y_pred` would already contain the decoded predictions,\n",
    "# but since we created the model in 'training' mode,\n",
    "# the model outputs raw predictions that still need to be decoded and filtered.\n",
    "# This is what the `decode_detections()` function is for.\n",
    "# It does exactly what the `DecodeDetections` layer would do,\n",
    "# but using Numpy instead of TensorFlow (i.e. on the CPU instead of the GPU).\n",
    "\n",
    "# `decode_detections()` with default argument values follows the procedure of the original SSD implementation:\n",
    "# First, a very low confidence threshold of 0.01 is applied to filter out the majority of the predicted boxes,\n",
    "# then greedy non-maximum suppression is performed per class with an intersection-over-union threshold of 0.45,\n",
    "# and out of what is left after that, the top 200 highest confidence boxes are returned.\n",
    "# Those settings are for precision-recall scoring purposes though.\n",
    "# In order to get some usable final predictions, we'll set the confidence threshold much higher, e.g. to 0.5,\n",
    "# since we're only interested in the very confident predictions.\n",
    "\n",
    "# 4: Decode the raw predictions in `y_pred`.\n",
    "\n",
    "y_pred_decoded = decode_detections(y_pred,\n",
    "                                   confidence_thresh=0.35,\n",
    "                                   iou_threshold=0.4,\n",
    "                                   top_k=200,\n",
    "                                   normalize_coords=normalize_coords,\n",
    "                                   img_height=img_height,\n",
    "                                   img_width=img_width)\n",
    "\n",
    "# We made the predictions on the resized images,\n",
    "# but we'd like to visualize the outcome on the original input images,\n",
    "# so we'll convert the coordinates accordingly.\n",
    "# Don't worry about that opaque `apply_inverse_transforms()` function below,\n",
    "# in this simple case it just applies `(* original_image_size / resized_image_size)` to the box coordinates.\n",
    "\n",
    "# 5: Convert the predictions for the original image.\n",
    "\n",
    "y_pred_decoded_inv = apply_inverse_transforms(y_pred_decoded, batch_inverse_transforms)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "print(y_pred_decoded_inv[i])\n",
    "\n",
    "# Finally, let's draw the predicted boxes onto the image.\n",
    "# Each predicted box says its confidence next to the category name.\n",
    "# The ground truth boxes are also drawn onto the image in green for comparison.\n",
    "\n",
    "# 5: Draw the predicted boxes onto the image\n",
    "\n",
    "# Set the colors for the bounding boxes\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(batch_original_images[i])\n",
    "\n",
    "current_axis = plt.gca()\n",
    "\n",
    "for box in batch_original_labels[i]:\n",
    "    xmin = box[1]\n",
    "    ymin = box[2]\n",
    "    xmax = box[3]\n",
    "    ymax = box[4]\n",
    "    label = '{}'.format(classes[int(box[0])])\n",
    "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color='green', fill=False, linewidth=2))\n",
    "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor': 'green', 'alpha': 1.0})\n",
    "\n",
    "# for box in y_pred_decoded_inv[i]:\n",
    "#     xmin = box[2]\n",
    "#     ymin = box[3]\n",
    "#     xmax = box[4]\n",
    "#     ymax = box[5]\n",
    "#     color = colors[int(box[0])]\n",
    "#     label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
    "#     current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))\n",
    "#     current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor': color, 'alpha': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
